### Paper Comments
- [Rudin et al. (2022): Interpretable machine learning: Fundamental principles and 10 grand challenges](https://projecteuclid.org/journals/statistics-surveys/volume-16/issue-none/Interpretable-machine-learning-Fundamental-principles-and-10-grand-challenges/10.1214/21-SS133.full). Very good, very opinionated position paper on interpretable machine learning. The paper provides a strong case why building models that are structurally interpretable is favorable (over first training a network and then post-hoc interpreting what it does). Albeit, I agree with the general argument I am not sure if I fully buy it: As of now, for many problems it seems to be the case that it is much easier to build black boxes than grey/white boxes (Purely empirically speaking). And, as long as this is the case, I think that post-hoc methods can provide a lot of value,  
- [Chauhan et al. (2023): A Brief Review of Hypernetworks in Deep Learning](https://arxiv.org/abs/2306.06955). Good overview of the state and use of hypernetworks. 
- [Roberts et al. (2017): Cross-validation strategies for data with temporal, spatial, hierarchical, or phylogenetic structure](https://onlinelibrary.wiley.com/doi/10.1111/ecog.02881). One of the few review papers on cross-validation that I know. Even better: Its a good and informative read. I would say it has a lot of breath, but not much depth. 
- [Melis, Kočiský, & Blunsom: Mogrifier LSTM](https://arxiv.org/abs/1909.01792). Interesting, but a bit too late for its time. 
- [Lee, Yao and Finn (2023): Diversify and Disambiguate: Out-of-Distribution Robustness via Disagreement](https://openreview.net/forum?id=RVTOp3MwT3n). I like the idea --- but am probably a bit biased since I had a similar idea once. I am not sure about the actual implementation yet. 
- [Vahidi et al. (2023): Diversified Ensemble of Independent Sub-Networks for Robust Self-Supervised Representation Learning](https://arxiv.org/abs/2308.14705). I am not so much interested in the self-supervised part of this. However, I really like (diversified) ensemble. Tangent: It is interesting that some fields use ensembles so often, but others almost never. I hope I can contribute at some point to the research on or with ensembles. 
- [Freiesleben & Grote (2023): Beyond generalization: a theory of robustness in machine learning](https://link.springer.com/article/10.1007/s11229-023-04334-9). An interesting "let us think about a concept out loud paper". For me this is the best discussion about the meaning of robustness in machine learning that I read so far. 
- [Schölkopf et al. (2021): Toward Causal Representation Learning](https://ieeexplore.ieee.org/abstract/document/9363924). This is an extremely good overview of what casual representation learning could be or become. I especially like how the authors contrast statistical and causal models. 
- [Jain et al. (2023): A Data-Based Perspective on Transfer Learning](https://openaccess.thecvf.com/content/CVPR2023/html/Jain_A_Data-Based_Perspective_on_Transfer_Learning_CVPR_2023_paper.html). Very interesting paper that provides a more nuanced view on transfer learning by looking at the data. They provide a strong argument for data curation. For example: among other things they find that more data is not in itself good, and one can also improve downstream performance by removing data from pretraining. 
- [Ting et al. (2023): Model Calibration and Validation From A Statistical Inference Perspective](https://arxiv.org/abs/2309.08562). This is an deep, thorough, but also opinionated overview about the principles of model calibration and validation in transport research (read: cars/traffic). Because of its theoretical nature and clear writing it is also a good read for people form different domains (like me). That said, in my opinion, some claims are formulated too strongly. 
- [Burnell et al. (2023): Rethink reporting of evaluation results in AI](https://www.science.org/doi/full/10.1126/science.adf6369?casa_token=k5ZRhKbip0YAAAAA%3AHzZ5Q7KqykNs3ODXziIKCoySYSrwbTdnxHvokJadWW0SiOompWQX8PcQzrVevCOSb-Uxc8AnPBNaTpU). Opinion paper that argues for a more thorough evaluation of machine learning models. Specifically, the authors propose to not (exclusively) focus on aggregate metrics. Strong agree. 
- [Frank, Fiedler, & Crevel (2021): Balancing potential of natural variability and extremes in photovoltaic and wind energy production for European countries](https://www.sciencedirect.com/science/article/pii/S0960148120311794). Thinks about how one can stabilize European renewables by cross country compensation schemes (in a purely renewable setting). Quite technical --- and at least for mem, as a non-expert, the paper was difficult to read. Still idea, topic, and approach are truly interesting. Looking forward to read follow ups to this one. 
- [Caruana (1997): Transfer Learning](https://link.springer.com/article/10.1023/a:1007379606734). The OG multitask learning paper. Its actually suprisingly deep. Much deeper than one would think from reading current multitask papers. 
- [Agned et al., (2021): Deep learning hybrid model with Boruta-Random forest optimiser algorithm for streamflow forecasting with climate mode indices, rainfall, and periodicity](https://www.sciencedirect.com/science/article/pii/S0022169421003978). Crazy model that combines a special random forest with an LSTM to do streamflow forecasting. Only very few basins are used. Not sure if I buy the results. 
- [Bhasme, Vagadiya & Bhatia (2021): Enhancing predictive skills in physically-consistent way: Physics Informed Machine Learning for Hydrological Processes](https://arxiv.org/abs/2104.11009). A PINN approach for streamflow prediction of single catchments. NOt very concincing.
- [Liu et al. (2022): Landscape Learning for Neural Network Inversion](https://arxiv.org/abs/2206.09027). I am very interested in the kind of ivnerstion they are describing and, at first sight, I like their proposed solution. I have to think more about it and learn more about this style of approaches.  
- [Foret et al. (2021): Sharpness-Aware Minimization for Efficiently Improving Generalization](https://arxiv.org/abs/2010.01412). Maybe the paper is a bit too much focused on theory to appeal to someone like me. Still, I find the idea(s) behind SAM quite cool. 
- [Manchingal and Cuzzolin (2022): Epistemic Deep Learning](https://arxiv.org/abs/2206.07609). Very broad overview of many different things. I like the intention of the proposed Epistemic Deep Learning program, but got lost in the paper. Whats worse: I am a bit sceptical about the experimental section since they do not compare themsevles to sota and have no image net. For many approaches that is fine, but here it seems off. 
- [Chouraqui et al. (2022): A Geometric Method for Improved Uncertainty Estimation in Real-time](https://arxiv.org/pdf/2206.11562.pdf). A geometrical approach for uncertainty prediction based on the input-label relationship of classifier models. The exposition is perhaps overly technical, but I still like the approach. Also, I am a bit criticall whether the distance based notions / hyperspheres works well on very high dimensional data. Maybe I am worng. 
- [Guo et al. (2017): On Calibration of Modern Neural Networks](https://proceedings.mlr.press/v70/guo17a.html). Interesting analysis of the uncertainty prediction capacities of many networks. 
- [Zhe Liu et al. (2022): A Simple Approach to Improve Single-Model Deep Uncertainty via Distance-Awareness](https://arxiv.org/abs/2205.00403). I like the initial discussion and the motivation of the paper. I think all their intuitions are the right ones. However, I don't think that it is a simple approach – and, I am not super convinced by the use of GPs and the enforcement of distance awareness into the last layer. 
- [Fannjiang et al. (2022): Conformal Prediction for the Design Problem](https://arxiv.org/abs/2202.03613). Very torough paper discussing an extremely interesting setting: The design problem - setting where the performance on a training set influences the shift on the test-set. 
- [He et al. (2022): NeMF: Neural Motion Fields for Kinematic
Animation](https://arxiv.org/abs/2206.03287). Super clever use of implicit neural representations. I wish I had an use for something like that. 
- [Wolleb et al. (2022): Diffusion Models for Medical Anomaly Detection](https://arxiv.org/abs/2203.04306). Very clever use of diffusion models for anomaly detection. I am not sure about the evaluation though. 
- [Douven (2021): Scoring, Truthlikeness, and Value](https://link.springer.com/article/10.1007/s11229-021-03162-z). A very interesting article about the interellation of model performance in terms of scoring rules and the value the models produce. Douven argue, quite convincingly, that there exist no single scoring rule (proper or not) that perfectly reflects the value of the prediction. 
- [Sousa (2022): Inductive Conformal Prediction: A Straightforward Introduction with Examples in Python](https://arxiv.org/abs/2206.11810). A very brief but very well written introduction to conformal prediction (a type of coverage based uncertaitny prediction for arbitrary models). 
- [Hüllermeier and Wageman (2020): Aleatoric and epistemic uncertainty in machine learning: an introduction to concepts and methods](https://link.springer.com/article/10.1007/s10994-021-05946-3). Perhaps the best introductory paper about uncertainty estimation for ML. The text has both breath and depth. It is well written, very clear explanations and examples. Even touches on conformal predictions and the like.
- Huber (2002): Approximate models. An extremely well written essays about model fitting, robustness and simulation. 
- [Zhang et al. (2021): Understanding plastic degradation and microplastic formation in the environment: A review](https://www.sciencedirect.com/science/article/pii/S0269749121001329). Interesting overview for someone like me who has very little insight to topic. 
- [Wortsman et al. (2022): Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time](https://arxiv.org/abs/2203.05482). Very interesting approach to obtain flat minima. I think i still prefer ensembles, but with the very large model paradigm we are in these might be the next-best thing.
- [Simon (1995): Artificial Intelligence: an empirical science](https://www.sciencedirect.com/science/article/pii/000437029500039H). An AI landmark paper before the advent of Deep Learning. A long read and at times a bit outdates. However, on a larger level it provides some very sharp arguments that are still relevant for todays discussion. 
- [Bengs, Hüllermeier, and Wageman (2022): On the Difficulty of Epistemic Uncertainty Quantification in Machine Learning: The Case of Direct Uncertainty Estimation through Loss Minimisation]. Very cool paper, which shows that is is difficult (and sometimes perhpas impossible) to learn higher order uncetainties (here already 2nd order uncertainty, i.e. Bayesian).
- [Post et al. (2021): Application of Laser-Induced, Deep UV Raman Spectroscopy and Artificial Intelligence in Real-Time Environmental Monitoring—Solutions and First Results](https://www.mdpi.com/1424-8220/21/11/3911). A paper that lines out pathways for ubiquitous microplastic monitoring. Intersting topic, but boring read. 
- [Petropolous et al. (2022): Forecasting: theory and practice](https://www.sciencedirect.com/science/article/pii/S0169207021001758?via%3Dihub). Because of its size and scope it seems pretty useless to me. Maybe a good reference. 
- [Tatsunami and Taki (2022): Sequencer: Deep LSTM for Image Classification](https://arxiv.org/abs/2205.01972). One of these papers that corroborate that with large amounts of data the learning algorithms matter less and less. In this case they show that LSTMs obtain competitive performance for large-scale image data. Very impressive engineering.
- [Cha, Chun, Lee, Cho, Park, Lee, and Park (2021): SWAD: Domain Generalization by Seeking Flat Minima](https://proceedings.neurips.cc/paper/2021/hash/bcb41ccdc4363c6848a1d760f26c28a0-Abstract.html). A flat-minima paper. They show a quite interesting technique to find flat-minima and empirical evidence that flat minima tend to generalize better than sharp ones. 
- [Shi, Daunhawer, Vogt, Torr, and Sanyal (2022): How robust are pre-trained models to distribution shift?](https://arxiv.org/abs/2206.08871): Empirical evidence that unsupervised models outperform supervised models regarding OOD generalization. 
- [Yiou, Jézéquel, Naveau, Otto, Vautard, and Vrac (2017): A statistical framework for conditional extreme event attribution](https://ascmo.copernicus.org/articles/3/17/2017/). An overview of a method to use counterfactual-analysis for assessing whether kinds of extreme events have become more or less likely due to Climate Change. Some things in there are hard to swallow, but great concept. 
- [Lloyd, Oreskes (2019): Climate Change Attribution: When Does it Make Sense to Add Methods?](https://www.pdcnet.org/eps/content/eps_2019_0056_0001_0185_0201). This contribuztion is easy to read and gives a great overview of different appraoches to assess the impact of climate change on extreme events. For my taste it is a bit to opinionated and almost prosaic from time to time. Still worth the read. 
- [Katz, Parlange, and Naveau (2002): Statistics of extremes in hydrology](https://doi.org/10.1016/S0309-1708(02)00056-8). A good overview of the uses of extreme value theory in hydrology. Perhaps needs an udpate. 
- [Foorgione, Muni, Piga, and Gallieri (2022): On the adaptation of recurrent neural networks for system identification](https://arxiv.org/abs/2201.08660). Interstingly enough system identificaiton is an interesting, but for ML unconventional, setting. The idea of the authors is to use that setting to study how RNNs that have been used for system identification purposes can be adjusted to eventual changes in the underlyign system as fast as possible. They propose to use an approximation to an updated model using a sort-of taylor expansion technique. This approximation yields a linearization of the loss-landscape around the current model parameters and lets them directly estimate a potential updade in a Kalman-like forward step. The exposition is good and the results are convincing.  
- [Baartman, Melsen, Moore, and van der Ploeg (2020): On the complexity of model complexity: Viewpoints across the geosciences](https://doi.org/10.1016/j.catena.2019.104261). This contribution gives an interesting take on model complexity. Instead of going trough formal or classical definitions of complexity the authors decided to design a questionaire and actually ask geo-scientist. Instead of deriving yet another definition of model complexity (which would probably be limited, like all current one), the authors emphasize that their results reflect that complexity is a context dependent property. I am not sure if I buy that. 
- [Gontijo-Lopes, Dauphin, and Cubuk (2021): No One Representation to Rule Them All: Overlapping Features of Training Methods](https://arxiv.org/abs/2110.12899). For me this was one of the most interseeting paper at neurips2021. The authors show that one can build super diverse ensembles with neural networks, if the same network is trained with different enough training methods (new self-supervised, state-of-the-art approaches lend themselves more to that than plain supervised ones). 
- [Khintchine (1934): Korrelationstheorie der stationären stochastischen Prozesse](https://link.springer.com/article/10.1007/BF01449156). One of the earliest paper that pins down the concept of stationarity and instationarity. Requires knowledge of german and some patience. Quite precise. 
- [Koutsoyiannis and Sargentis (2021): Entropy and Wealth Demetris](https://www.mdpi.com/1099-4300/23/10/1356). A mathematical essay on the connection between entropy and wealth. True out of the box thinking. 
- [Beven (2020): The era of infiltration
Keith](https://doi.org/10.5194/hess-25-851-2021). Historical inquiry about infiltration theory by one of the most important hydrologist alive. Worth reading for everyone who is itnerested in the history of quantitative hydrology.
- [Merz et al. (2021): Causes, impacts and patterns of disastrous river floods](https://doi.org/10.1038/s43017-021-00195-3). QUite superficial review about the flood risks. Maybe good as a reference. 
- [Saltelli (2020): Ethics of quantification or quantification of ethics?](https://doi.org/10.1016/j.futures.2019.102509). I guess this is what "philosophy of data-science" looks like if it is done by a well read data-scientist (as opposed to a data-sciency philosopher)
- [Voita and Titov (2020)](https://arxiv.org/abs/2003.12298). Probing is cool and this is an excellent paper about how to make probes. 
- [Jain et al. (2021)](https://openreview.net/pdf?id=Jep2ykGUdS). A very cool paper about a quite involved method for uncertainty-estimation based active learning. 
- [Karandikar et al. (2021): Soft Calibration Objectives for Neural Networks](https://papers.nips.cc/paper/2021/file/f8905bd3df64ace64a68e154ba72f24c-Paper.pdf). I do have a heart for soft-appraoches and this seems to be a good idea. If I would actually work on calibration task I would try it for sure. 
- [Biloš et al. (2021): Neural Flows: Efficient Alternative to Neural ODEs](https://arxiv.org/abs/2110.13040). The paper presents an intersting alternative to neuralODE. I am (still) not sure if neuralODE are a good idea in the first place, but here is already an approach that might supersedes them. 
- [Judd and Stemler (2010): Forecasting: it is not about statistics, it is about dynamics](https://www.jstor.org/stable/25663247). When reading one can see that authors had very specific model classes in mind. Still, I quite like their framing and the (historical) view they present regarding the forecasting problem. 
- [Judd and Nakamura (2006): Degeneracy of time series models: The best model is not always the correct model](https://doi.org/10.1063/1.2213957). A very interesting paper that demonstrates on basis of a simple example that when we model a non-linear system and noisy measruements the best model is likely not the correct (i.e. true) model. Given the few citation it has, I think that the insight of the paper and the clearness of the example is underapreciated. 

![reading-papers](https://github.com/allokkio/openLearning/blob/master/img/paper-ideas.png?raw=true)
